huggingface:

Hugging Face is at the forefront of AI development, and I resonate deeply with your mission of advancing open AI research and making the best models accessible to all. Through client projects at UnleashAI and countless side projects, I have consistently relied on Hugging Face’s models and tools to build impactful AI solutions.

As a person, I am curious, hardworking, and driven by a passion for building AI systems that create real-world impact. I thrive in collaborative environments, enjoy tackling complex challenges, and have a strong track record of designing and deploying scalable AI solutions. I am always seeking ways to push the boundaries of what AI can achieve.

At Viasat, I developed an AI-powered executive summary generator, bringing AI automation to backend tooling. My work in AI automation consulting has also equipped me with the ability to translate complex problems into impactful, user-friendly AI-powered applications. With expertise in Python, PyTorch, and cloud infrastructure, I am eager to contribute to Hugging Face's dynamic team and inspiring mission.

Most interesting projects

One of the most interesting LLM-related projects I’ve worked on is an NLP-to-SQL chatbot I built for a client at UnleashAI.  The goal was to empower non-technical users to query structured databases using natural language, eliminating the need for them to write SQL.  This was particularly rewarding because it directly addressed a real pain point for the client, making their data much more accessible.

To achieve accurate translations, I implemented a Retrieval Augmented Generation (RAG) system. This involved two key components: First, I enhanced query translation accuracy by retrieving past successful queries and database-specific syntax patterns. This allowed the chatbot to learn from previous interactions and adapt to the nuances of the client's specific database. Second, I leveraged schema metadata stored in a Pinecone vector database.  This allowed the chatbot to dynamically determine the correct database or databases to query, which was crucial as the client had multiple databases.

The chatbot itself used a Llama 3.2 model fine-tuned on SageMaker.  I chose this approach because fine-tuning allowed me to optimize the model specifically for the NLP-to-SQL task and the client's data.  This resulted in significantly improved performance compared to using a general-purpose LLM.

A major challenge in this project was preventing hallucinated or invalid SQL queries.  To address this, I developed adversarial testing frameworks.  These included execution accuracy testing to ensure queries returned the correct results, and Logical Form Equivalence Matching (LFEM) analysis to verify that generated SQL queries were functionally equivalent to reference queries, even if the syntax differed. I also implemented syntactic validation to catch errors before execution, further improving reliability.  Seeing the final system in action, and how it transformed data retrieval for the client, was incredibly satisfying.  It significantly improved query accuracy and made data accessible to everyone, regardless of their technical background.  That’s why this project is one of my proudest accomplishments involving LLMs.