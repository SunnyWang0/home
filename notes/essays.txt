huggingface:

Hugging Face is at the forefront of AI development, and I resonate deeply with your mission of advancing open AI research and making the best models accessible to all. Through client projects at UnleashAI and countless side projects, I have consistently relied on Hugging Face’s models and tools to build impactful AI solutions.

As a person, I am curious, hardworking, and driven by a passion for building AI systems that create real-world impact. I thrive in collaborative environments, enjoy tackling complex challenges, and have a strong track record of designing and deploying scalable AI solutions. I am always seeking ways to push the boundaries of what AI can achieve.

At Viasat, I developed an AI-powered executive summary generator, bringing AI automation to backend tooling. My work in AI automation consulting has also equipped me with the ability to translate complex problems into impactful, user-friendly AI-powered applications. With expertise in Python, PyTorch, and cloud infrastructure, I am eager to contribute to Hugging Face's dynamic team and inspiring mission.

Scale AI:

One of the most interesting LLM-related projects I’ve worked on is an NLP-to-SQL chatbot I built for a client at UnleashAI. The goal was to enable non-technical users to query structured databases using natural language, eliminating the need for manual SQL queries. To ensure accurate translations, I implemented retrieval-augmented generation (RAG) in two key ways: first, by retrieving past successful queries and database-specific syntax patterns to improve query translation accuracy, and second, by leveraging schema metadata stored in a vector database to dynamically determine the correct database to query. The chatbot used the best-performing SQL generation model from Hugging Face, as ranked by the SQL-Eval 2 benchmark, ensuring state-of-the-art performance.

A major challenge was preventing hallucinated or invalid SQL queries, so I developed adversarial testing frameworks to evaluate the chatbot’s robustness. This included execution accuracy (EX) testing, ensuring queries returned the correct results, and logical form exact match (LFEM) analysis, verifying that generated SQL queries were functionally equivalent to reference queries. Additionally, I implemented syntactic validation to catch errors before execution, improving reliability. The final system significantly improved query accuracy while reducing manual data retrieval time by 40%. This project aligns well with Scale AI’s focus on LLM robustness, prompt engineering, and evaluation methodologies. It also demonstrates my ability to design and optimize LLM-powered applications, conduct adversarial testing, and implement scalable AI solutions—all critical to advancing AI safety and reliability.
